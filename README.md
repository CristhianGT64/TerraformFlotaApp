# Arquitectura Terraform - Flota de VehÃ­culos

Proyecto de infraestructura en Azure utilizando Terraform para la gestiÃ³n de una flota de vehÃ­culos blindados con anÃ¡lisis de datos en tiempo real.

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa una infraestructura completa en Azure usando Terraform para una empresa de seguridad y logÃ­stica que lanza una aplicaciÃ³n de renta de vehÃ­culos blindados. La plataforma debe:

âœ… Gestionar operaciones en tiempo real: reservas, contratos y estado de la flota
âœ… Permitir analÃ­tica avanzada sin afectar las operaciones transaccionales
âœ… Soportar dos cargas de trabajo separadas: OLTP (operacional) y OLAP (analÃ­tica)

## ğŸ—ï¸ Diagrama de Arquitectura

![Arquitectura Terraform Flota Vehiculos](./images/arquitecturaTerraform.png)

---

## ğŸ“– GuÃ­a Paso a Paso: ImplementaciÃ³n del Proyecto

### Checklist de PreparaciÃ³n

Antes de comenzar, debemos tener instalado:

- âœ… Cuenta de Azure con suscripciÃ³n activa
- âœ… Azure CLI instalado y configurado
- âœ… Terraform instalado (versiÃ³n 1.0+)
- âœ… Git instalado
- âœ… Cuenta de GitHub
- âœ… Editor de cÃ³digo (VS Code recomendado)

---

## ğŸ›ï¸ JustificaciÃ³n de Servicios

### Requisito 1: Base de Datos Transaccional
**Servicio:** Azure SQL Database

Base de datos relacional completamente administrada con alta disponibilidad (SLA 99.99%), escalado automÃ¡tico, respaldos integrados y baja latencia. Ideal para operaciones transaccionales de reservas y contratos en tiempo real.

### Requisito 2: Almacenamiento AnalÃ­tico
**Servicio:** Azure Data Lake Storage Gen2 (ADLS Gen2)

Almacenamiento optimizado para Big Data con soporte nativo para archivos JSON, particionamiento jerÃ¡rquico y alto rendimiento para anÃ¡lisis batch. IntegraciÃ³n directa con servicios de procesamiento como Databricks y Synapse.

### Requisito 3: OrquestaciÃ³n de Datos
**Servicio:** Azure Data Factory

Servicio ETL/ELT serverless diseÃ±ado especÃ­ficamente para pipelines batch programados. Permite copiar datos de SQL a Data Lake con transformaciones, monitoreo integrado y triggers temporales sin gestionar infraestructura.

### Requisito 4: Plataforma de AnÃ¡lisis
**Servicio:** Azure Databricks

Plataforma de anÃ¡lisis colaborativa con notebooks, soporte completo para Apache Spark, ideal para procesar telemetrÃ­a compleja en JSON y realizar anÃ¡lisis avanzados de patrones de uso y rentabilidad.

### Requisito 5: GestiÃ³n de Secretos
**Servicio:** Azure Key Vault

AlmacÃ©n seguro centralizado para credenciales, cadenas de conexiÃ³n y secretos. Control de acceso mediante RBAC, auditorÃ­a completa e integraciÃ³n nativa con todos los servicios Azure.

---

## ğŸ“¸ Evidencia de Despliegue

### 1ï¸âƒ£ ComprobaciÃ³n de Cambios (terraform plan)

![Comprobacion de cambios](./images/Imagen2.png)

En esta captura se realiza la comprobaciÃ³n de los Ãºltimos cambios. Se muestra el resultado del comando `terraform plan`, que detalla todos los cambios finales a implementar para la arquitectura desplegada en Azure.

---

### 2ï¸âƒ£ EjecuciÃ³n de Apply (terraform apply)

![Ejecucion de Apply](./images/Imagen3.png)

AquÃ­ se ejecuta la orden `terraform apply` para desplegar los cambios hacia Azure. La terminal muestra:
- âœ… La orden estÃ¡ formada y lista
- â³ Solicita confirmaciÃ³n (respuesta: `yes`)
- ğŸ“‹ Breve descripciÃ³n de los cambios que se realizarÃ¡n
- ğŸ”„ QuÃ© servicios se modificarÃ¡n y aplicarÃ¡n en la estructura

---

### 3ï¸âƒ£ ConfirmaciÃ³n de Ã‰xito (Apply Completado)

![Exito de Apply](./images/Imagen4.png)

ConfirmaciÃ³n desde los servidores de Azure de que los cambios se completaron exitosamente. Se muestra:
- âœ… Estado: **Completado**
- ğŸ“Š Tipos de cambios realizados
- â±ï¸ **Tiempo total:** 2 minutos 30 segundos (Databricks tardÃ³ ~10 minutos)

---

### 4ï¸âƒ£ VerificaciÃ³n en Azure Portal

![Azure](./images/Imagen5.png)

ConfirmaciÃ³n visual desde la GUI de Azure. Se verifica que:
- âœ… Todos los servicios se desplegaron exitosamente
- ğŸ“¦ Los recursos configurados en Terraform estÃ¡n presentes
- ğŸ¢ La arquitectura completa estÃ¡ operativa en Azure


## ğŸ’­ Reflexiones Finales

### 1. DesafÃ­o Mayor: Dependencias ImplÃ­citas en Terraform

**Problema identificado:**  
Terraform creÃ³ Key Vault antes que SQL Database, pero intentÃ³ almacenar el `sql-connection-string` simultÃ¡neamente, causando un error de "secret cannot be created before vault is ready".

**SoluciÃ³n implementada:**  
AgreguÃ© `depends_on = [azurerm_key_vault.kv]` en todos los secretos para forzar la secuencia:
1. Key Vault se crea completamente
2. SQL Database se crea
3. Secretos se almacenan

**LecciÃ³n aprendida:**  
Aunque Terraform infiere dependencias de variables (`azurerm_key_vault.kv.id`), las operaciones asÃ­ncronas de Azure pueden requerir dependencias explÃ­citas para garantizar que el recurso estÃ© "completamente listo".

### 2. SeparaciÃ³n OLTP/OLAP en Alquiler de VehÃ­culos

**Â¿Por quÃ© separar?**

| Aspecto | OLTP (SQL Database) | OLAP (Data Lake + Databricks) |
|---------|---------------------|-------------------------------|
| **Tipo de consultas** | Transacciones puntuales (INSERT/UPDATE) | Agregaciones complejas (GROUP BY, JOINs masivos) |
| **Latencia** | Milisegundos | Segundos/minutos |
| **Volumen de datos** | Registros actuales (Ãºltimos 6 meses) | HistÃ³ricos completos (aÃ±os) |
| **Usuarios** | Sistema de reservas (miles de req/s) | Analistas (5-10 usuarios) |


# ğŸš— Plataforma de Alquiler de VehÃ­culos Blindados - Terraform Project

![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)
![Terraform](https://img.shields.io/badge/Terraform-7B42BC?style=for-the-badge&logo=terraform&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Arquitectura de la SoluciÃ³n](#-arquitectura-de-la-soluciÃ³n)
- [JustificaciÃ³n de Servicios](#-justificaciÃ³n-de-servicios-azure)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Requisitos Previos](#-requisitos-previos)
- [Instrucciones de Despliegue](#-instrucciones-de-despliegue)
- [Evidencias de Despliegue](#-evidencias-de-despliegue)
- [Reflexiones Finales](#-reflexiones-finales)
- [Recursos y Referencias](#-recursos-y-referencias)

---

## ğŸ“– DescripciÃ³n del Proyecto

Este proyecto implementa una **infraestructura completa en Azure** usando **Terraform** para una empresa de seguridad y logÃ­stica que lanza una aplicaciÃ³n de renta de vehÃ­culos blindados. La plataforma debe:

- âœ… Gestionar operaciones en tiempo real: reservas, contratos y estado de la flota
- âœ… Permitir analÃ­tica avanzada sin afectar las operaciones transaccionales
- âœ… Soportar dos cargas de trabajo separadas: **OLTP** (operacional) y **OLAP** (analÃ­tica)

---

## ğŸ—ï¸ Arquitectura de la SoluciÃ³n

### Diagrama de Arquitectura

![Arquitectura](./diagrams/arquitectura-completa.svg)

### Componentes Principales

| Capa | Servicio Azure | PropÃ³sito |
|------|---------------|-----------|
| **OLTP** | Azure SQL Database | Base transaccional de alta disponibilidad |
| **OLAP** | Azure Data Lake Gen2 | Almacenamiento de histÃ³ricos y telemetrÃ­a |
| **OrquestaciÃ³n** | Azure Data Factory | Pipeline ETL batch programado |
| **AnÃ¡lisis** | Azure Databricks | Notebooks con Apache Spark |
| **Seguridad** | Azure Key Vault | GestiÃ³n centralizada de secretos |

### Flujo de Datos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Azure SQL DB   â”‚â”€â”€ETLâ”€â”€>â”‚  Data Factory    â”‚â”€â”€Loadâ”€>â”‚  Data Lake Gen2 â”‚
â”‚     (OLTP)      â”‚        â”‚   (Batch Job)    â”‚        â”‚     (OLAP)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                 â”‚
                                                                 â–¼
                                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                        â”‚   Databricks    â”‚
                                                        â”‚   (Analytics)   â”‚
                                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Key Vault      â”‚â—„â”€â”€â”€â”€â”€â”€â”€ Todos los servicios
                           â”‚   (Secrets)      â”‚         consultan secretos
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ JustificaciÃ³n de Servicios Azure

### **Requisito 1: Base de Datos Transaccional**

**Servicio:** `Azure SQL Database`

**JustificaciÃ³n:**
- âœ… **Alta disponibilidad:** SLA de 99.99% con respaldos automÃ¡ticos
- âœ… **Baja latencia:** Optimizada para operaciones CRUD transaccionales
- âœ… **Escalabilidad:** Permite ajustar DTUs segÃºn demanda
- âœ… **Seguridad:** Cifrado en trÃ¡nsito y reposo, firewall integrado
- âœ… **Compatibilidad:** Soporte completo para SQL Server estÃ¡ndar

**Alternativas consideradas:**
- MySQL/PostgreSQL: Menor integraciÃ³n con el ecosistema Azure
- Cosmos DB: Sobrecosto para un modelo relacional estÃ¡ndar

---

### **Requisito 2: Almacenamiento AnalÃ­tico**

**Servicio:** `Azure Data Lake Storage Gen2`

**JustificaciÃ³n:**
- âœ… **Optimizado para Big Data:** DiseÃ±ado para anÃ¡lisis masivos con Spark/Hadoop
- âœ… **Soporte JSON nativo:** Ideal para logs de telemetrÃ­a sin transformaciones
- âœ… **Particionamiento jerÃ¡rquico:** OrganizaciÃ³n eficiente de histÃ³ricos
- âœ… **IntegraciÃ³n perfecta:** ConexiÃ³n directa con Databricks y Data Factory
- âœ… **Costo-efectivo:** Tier de acceso esporÃ¡dico para datos histÃ³ricos

**Alternativas consideradas:**
- Blob Storage estÃ¡ndar: Sin optimizaciones para anÃ¡lisis distribuido
- Azure Synapse (solo): Sobrecosto si no se requiere DWH completo

---

### **Requisito 3: OrquestaciÃ³n de Datos**

**Servicio:** `Azure Data Factory`

**JustificaciÃ³n:**
- âœ… **Serverless:** Sin gestiÃ³n de infraestructura subyacente
- âœ… **Conectores nativos:** Copy Activity optimizada para SQL â†’ Data Lake
- âœ… **ProgramaciÃ³n integrada:** Triggers temporales con cron-like expressions
- âœ… **Monitoreo y alertas:** Dashboard visual para seguimiento de pipelines
- âœ… **Transformaciones:** Data Flow para limpieza y conversiÃ³n de datos

**Ventajas sobre scripts manuales:**
1. **Resiliencia:** Reintentos automÃ¡ticos ante fallos
2. **Escalabilidad:** ParalelizaciÃ³n automÃ¡tica de copias
3. **AuditorÃ­a:** Logs detallados de cada ejecuciÃ³n
4. **Mantenibilidad:** GUI para modificar pipelines sin cÃ³digo

**Alternativas consideradas:**
- Cron job en VM: Requiere gestionar infraestructura y monitoreo
- Azure Functions: No optimizado para transferencias masivas de datos

---

### **Requisito 4: Plataforma de AnÃ¡lisis**

**Servicio:** `Azure Databricks`

**JustificaciÃ³n:**
- âœ… **Apache Spark nativo:** Procesamiento distribuido de telemetrÃ­a compleja
- âœ… **Notebooks colaborativos:** MÃºltiples analistas trabajando simultÃ¡neamente
- âœ… **LibrerÃ­as ML:** Scikit-learn, TensorFlow para modelos predictivos
- âœ… **IntegraciÃ³n Delta Lake:** ACID transactions sobre Data Lake
- âœ… **Auto-escalado:** Clusters elÃ¡sticos segÃºn carga de trabajo

**Casos de uso especÃ­ficos:**
- AnÃ¡lisis de patrones de uso (clustering de comportamientos)
- PredicciÃ³n de mantenimiento preventivo (modelos de ML)
- OptimizaciÃ³n de rutas y rentabilidad por vehÃ­culo

**Alternativas consideradas:**
- HDInsight: Menor integraciÃ³n y requiere mÃ¡s configuraciÃ³n manual
- Azure Synapse Spark: VÃ¡lido, pero Databricks tiene mejor UX para data science

---

### **Requisito 5: GestiÃ³n de Secretos**

**Servicio:** `Azure Key Vault`

**JustificaciÃ³n:**
- âœ… **CentralizaciÃ³n:** Un Ãºnico punto para todas las credenciales
- âœ… **Control de acceso:** RBAC granular por servicio/usuario
- âœ… **AuditorÃ­a completa:** Logs de quiÃ©n accediÃ³ a quÃ© secreto y cuÃ¡ndo
- âœ… **IntegraciÃ³n nativa:** Todos los servicios Azure soportan Key Vault
- âœ… **RotaciÃ³n automÃ¡tica:** PolÃ­ticas de renovaciÃ³n de credenciales

**Secretos almacenados:**
- Connection strings de SQL Database
- Access keys de Data Lake
- URLs de Databricks
- Credenciales de servicios externos

---

## ğŸ“ Estructura del Proyecto

```
terraform-vehiculos-blindados/
â”œâ”€â”€ main.tf                  # Recursos principales
â”œâ”€â”€ variables.tf             # DeclaraciÃ³n de variables
â”œâ”€â”€ outputs.tf               # Salidas del despliegue
â”œâ”€â”€ terraform.tfvars         # Valores de variables (NO subir a GitHub)
â”œâ”€â”€ .gitignore              # Excluye archivos sensibles
â”œâ”€â”€ README.md               # Este archivo
â””â”€â”€ diagrams/
    â””â”€â”€ arquitectura-completa.svg
```

### DescripciÃ³n de Archivos

- **`main.tf`**: Define todos los recursos Azure (SQL, Data Lake, Data Factory, Databricks, Key Vault)
- **`variables.tf`**: Declara variables reutilizables con tipos y descripciones
- **`outputs.tf`**: Expone informaciÃ³n clave tras el despliegue (endpoints, nombres)
- **`terraform.tfvars`**: Valores concretos para cada variable (agregar a `.gitignore`)

---

## âš™ï¸ Requisitos Previos

1. **Azure CLI** instalado y configurado:
   ```bash
   az login
   az account set --subscription "<SUBSCRIPTION_ID>"
   ```

2. **Terraform** instalado (v1.0+):
   ```bash
   terraform --version
   ```

3. **Permisos en Azure:**
   - Contributor en la suscripciÃ³n
   - Permisos para crear Service Principals (Key Vault)

---

## ğŸš€ Instrucciones de Despliegue

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/TU_USUARIO/terraform-vehiculos-blindados.git
cd terraform-vehiculos-blindados
```

### Paso 2: Configurar Variables

Edita `terraform.tfvars` con tus valores:

```hcl
resource_group_name       = "rg-vehiculos-prod"
location                  = "eastus"
sql_server_name          = "sql-vehiculos-2025"
storage_account_name     = "datalakeveh2025"  # Â¡Debe ser Ãºnico globalmente!
```

### Paso 3: Inicializar Terraform

```bash
terraform init
```

### Paso 4: Validar ConfiguraciÃ³n

```bash
terraform validate
terraform plan
```

### Paso 5: Desplegar Infraestructura

```bash
terraform apply
```

Confirma escribiendo `yes` cuando se solicite.

### Paso 6: Verificar Outputs

```bash
terraform output
```

Ejemplo de salida:
```
databricks_workspace_url = "https://adb-123456789.10.azuredatabricks.net"
sql_server_fqdn = "sql-vehiculos-2025.database.windows.net"
```

---

## ğŸ“¸ Evidencias de Despliegue

### 1. Salida Exitosa de `terraform apply`

![Terraform Apply](./screenshots/terraform-apply.png)

**ExplicaciÃ³n:**  
Captura mostrando la creaciÃ³n exitosa de todos los recursos:
- 12 recursos agregados (`12 added`)
- 0 cambios o destrucciones
- Tiempo de ejecuciÃ³n: ~8 minutos

---

### 2. Resource Group en Azure Portal

![Azure Resource Group](./screenshots/azure-resource-group.png)

**ExplicaciÃ³n:**  
Vista del Resource Group `rg-alquiler-vehiculos` conteniendo:
- âœ… SQL Server + Database
- âœ… Storage Account (Data Lake Gen2)
- âœ… Data Factory
- âœ… Databricks Workspace
- âœ… Key Vault

---

### 3. Azure SQL Database Funcionando

![SQL Database](./screenshots/sql-database.png)

**ExplicaciÃ³n:**  
Base de datos `VehiculosDB` en tier S0 con:
- Estado: Online
- Firewall: Configurado para servicios Azure
- Backups: AutomÃ¡ticos cada 7 dÃ­as

---

### 4. Data Lake Gen2 con Contenedores

![Data Lake](./screenshots/data-lake-containers.png)

**ExplicaciÃ³n:**  
Storage Account con Hierarchical Namespace habilitado:
- Contenedor `historicos`: Para datos transaccionales histÃ³ricos
- Contenedor `telemetria`: Para logs JSON de vehÃ­culos

---

### 5. Data Factory con Linked Services

![Data Factory](./screenshots/data-factory.png)

**ExplicaciÃ³n:**  
Azure Data Factory configurado con:
- Managed Identity habilitada
- Linked Service a SQL Database
- Linked Service a Data Lake Gen2
- Permisos de escritura en Data Lake asignados

---

### 6. Databricks Workspace Activo

![Databricks](./screenshots/databricks-workspace.png)

**ExplicaciÃ³n:**  
Workspace de Databricks con:
- Tier: Standard
- Estado: Running
- URL: Guardada en Key Vault para acceso seguro

---

### 7. Key Vault con Secretos Almacenados

![Key Vault](./screenshots/key-vault-secrets.png)

**ExplicaciÃ³n:**  
Key Vault conteniendo:
- `sql-connection-string`: Cadena de conexiÃ³n a SQL
- `datalake-access-key`: Access key del Data Lake
- `databricks-workspace-url`: URL del workspace

---

## ğŸ’­ Reflexiones Finales

### 1. DesafÃ­o Mayor: Dependencias ImplÃ­citas en Terraform

**Problema identificado:**  
Terraform creÃ³ Key Vault antes que SQL Database, pero intentÃ³ almacenar el `sql-connection-string` simultÃ¡neamente, causando un error de "secret cannot be created before vault is ready".

**SoluciÃ³n implementada:**  
AgreguÃ© `depends_on = [azurerm_key_vault.kv]` en todos los secretos para forzar la secuencia:
1. Key Vault se crea completamente
2. SQL Database se crea
3. Secretos se almacenan

**LecciÃ³n aprendida:**  
Aunque Terraform infiere dependencias de variables (`azurerm_key_vault.kv.id`), las operaciones asÃ­ncronas de Azure pueden requerir dependencias explÃ­citas para garantizar que el recurso estÃ© "completamente listo".

**Otro ejemplo crÃ­tico:**  
Data Factory necesita su Managed Identity **antes** de asignar el rol `Storage Blob Data Contributor`. Usamos:
```hcl
resource "azurerm_role_assignment" "adf_storage_access" {
  principal_id = azurerm_data_factory.adf.identity[0].principal_id
  # Terraform espera automÃ¡ticamente a que .identity estÃ© disponible
}
```

---

### 2. SeparaciÃ³n OLTP/OLAP en Alquiler de VehÃ­culos

**Â¿Por quÃ© separar?**

| Aspecto | OLTP (SQL Database) | OLAP (Data Lake + Databricks) |
|---------|---------------------|-------------------------------|
| **Tipo de consultas** | Transacciones puntuales (INSERT/UPDATE) | Agregaciones complejas (GROUP BY, JOINs masivos) |
| **Latencia** | Milisegundos | Segundos/minutos |
| **Volumen de datos** | Registros actuales (Ãºltimos 6 meses) | HistÃ³ricos completos (aÃ±os) |
| **Usuarios** | Sistema de reservas (miles de req/s) | Analistas (5-10 usuarios) |

**Ejemplo prÃ¡ctico: Â¿QuÃ© pasa si NO separamos?**

Imagina que un analista ejecuta esta consulta sobre la BD de reservas:

```sql
SELECT vehiculo_id, AVG(duracion_alquiler), SUM(ingresos)
FROM reservas
WHERE fecha BETWEEN '2020-01-01' AND '2024-12-31'
GROUP BY vehiculo_id;
```

**Consecuencias:**
- âŒ **Bloqueos de tabla:** La consulta analÃ­tica compite con INSERTs de nuevas reservas
- âŒ **Latencia en la app:** Clientes experimentan tiempos de respuesta de 5-10 segundos
- âŒ **Consumo de recursos:** El DTU del SQL Database se satura al 100%
- âŒ **Posibles timeouts:** La aplicaciÃ³n web lanza excepciones de conexiÃ³n

**Con separaciÃ³n OLTP/OLAP:**
- âœ… Las consultas analÃ­ticas se ejecutan en Databricks sobre Data Lake (sin afectar SQL)
- âœ… El ETL nocturno (3 AM) copia datos cuando hay bajo trÃ¡fico de reservas
- âœ… La app de reservas mantiene latencias < 100ms consistentemente
- âœ… Los analistas pueden ejecutar queries de horas sin impactar operaciones

---

### 3. Importancia de Azure Data Factory vs Script Manual

**Escenario sin orquestaciÃ³n:**  
Un script Python con `cron` ejecutÃ¡ndose en una VM:

```python
# script_manual.py
import pyodbc
import os

conn = pyodbc.connect(os.getenv("SQL_CONN_STRING"))
cursor = conn.cursor()
cursor.execute("SELECT * FROM reservas WHERE fecha > '2024-01-01'")
# ... copiar a CSV y subir a Blob Storage ...
```

**Problemas de este enfoque:**

| Problema | Impacto | SoluciÃ³n con Data Factory |
|----------|---------|---------------------------|
| **Fallos silenciosos** | Si el script falla a las 3 AM, nadie se entera hasta que un analista reporta datos faltantes | Alertas automÃ¡ticas por email/Teams |
| **Sin reintentos** | Una desconexiÃ³n de red transitoria detiene todo | Retry logic con backoff exponencial |
| **No escalable** | Copiar 10M de registros toma 2 horas | ParalelizaciÃ³n automÃ¡tica con Copy Activity |
| **Mantenimiento de VM** | Actualizaciones de SO, parches de seguridad, monitoreo | Servicio completamente serverless |
| **Sin auditorÃ­a** | Â¿CuÃ¡ntos registros se copiaron? Â¿En quÃ© momento fallÃ³? | Dashboard con logs detallados |
| **Credenciales en cÃ³digo** | Connection strings en variables de entorno o peor, hardcoded | IntegraciÃ³n con Key Vault |




---

## ğŸ”§ Configurar Azure CLI

```bash
# Instalar Azure CLI 
# Windows: https://aka.ms/installazurecliwindows
# macOS: brew install azure-cli
# Linux: curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

# Iniciar sesiÃ³n
az login

# Verificar la suscripciÃ³n
az account show

# Establecer la suscripciÃ³n correcta
az account list --output table
az account set --subscription "NOMBRE_O_ID_DE_TU_SUSCRIPCION"
```

---

## ğŸš€ Instalar Terraform

```bash
# Verificar si ya estÃ¡ instalado
terraform --version

# Si no estÃ¡ instalado:
# Windows: Descargar de https://www.terraform.io/downloads
# macOS: brew install terraform
# Linux: 
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/
```

---

## ğŸ“¦ Clonar Repositorio

```bash
git clone https://github.com/MiltonAlvarado/arquitectura_terraform_flota_vehiculos.git
cd arquitectura_terraform_flota_vehiculos
```

---

## âš™ï¸ Personalizar Variables

Editar `terraform.tfvars` con los valores Ãºnicos que se tengan:

```hcl
resource_group_name = " "
location            = " "
sql_server_name     = " "
storage_account_name = " "  # Ãšnico globalmente!
data_factory_name    = " "
databricks_workspace_name = " "
key_vault_name       = " "  
```

**Nota importante:** El `storage_account_name` debe:
- Ser Ãºnico en todo Azure
- Contener solo letras minÃºsculas y nÃºmeros
- Tener entre 3-24 caracteres

---

## ğŸš¢ Desplegar Infraestructura

```bash
# 1. Inicializar Terraform
terraform init

# 2. Validar sintaxis
terraform validate

# 3. Ver quÃ© se va a crear 
terraform plan

# 4. Desplegar recursos 
terraform apply

# Cuando pregunte "Do you want to perform these actions?"
# Respuesta: yes
```

---

## ğŸ“Š EstimaciÃ³n de Costos

Recursos corriendo 24/7:

| Servicio        | Tier                | Costo Mensual (aprox.) |
|:---|:---|:---|
| SQL Database S0 | 10 DTU              | ~$15 USD               |
| Storage Account | Standard LRS        | ~$5 USD                |
| Data Factory    | Sin pipeline activo | ~$1 USD                |
| Databricks      | Sin cluster activo  | ~$0 USD                |
| Key Vault       | Standard            | ~$1 USD                |
| **TOTAL**       | -                   | **~$22 USD/mes**       |

---

## ğŸ“ Licencia

Este proyecto es de uso educativo.

---

## ğŸ‘¨â€ğŸ’» Autor

Proyecto creado como parte del programa de Sistemas Expertos.


#   T e r r a f o r m F l o t a A p p  
 